#!/usr/bin/env python3
"""
ğŸš€ æ€§èƒ½ç“¶é¢ˆè¯Šæ–­è„šæœ¬
ä¸“é—¨ç”¨äºåˆ†æAPIå“åº”æ—¶é—´ä¸SQLæŸ¥è¯¢æ—¶é—´çš„å·¨å¤§å·®è·
"""

import time
import requests
import logging
import threading
import psutil
import json
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PerformanceBottleneckDiagnoser:
    def __init__(self):
        self.base_url = "http://localhost:8080/v2"
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "api_tests": [],
            "concurrent_tests": [],
            "bottleneck_analysis": {},
            "recommendations": []
        }
    
    def test_single_api_detailed(self, endpoint: str, description: str = ""):
        """è¯¦ç»†æµ‹è¯•å•ä¸ªAPIçš„æ€§èƒ½åˆ†è§£"""
        url = f"{self.base_url}{endpoint}"
        logger.info(f"ğŸ” è¯¦ç»†æµ‹è¯•: {description} - {url}")
        
        try:
            # ğŸš€ åˆ†æ®µæµ‹è¯•
            times = {}
            
            # 1. è¿æ¥å»ºç«‹æ—¶é—´
            times['start'] = time.time()
            
            # 2. å‘é€è¯·æ±‚
            response = requests.get(url, timeout=30)
            times['response_received'] = time.time()
            
            # 3. æ•°æ®è§£ææ—¶é—´
            try:
                data = response.json()
                times['json_parsed'] = time.time()
                data_size = len(json.dumps(data))
            except:
                data = None
                data_size = len(response.content) if response.content else 0
                times['json_parsed'] = times['response_received']
            
            # è®¡ç®—å„é˜¶æ®µè€—æ—¶
            total_time = (times['response_received'] - times['start']) * 1000
            parsing_time = (times['json_parsed'] - times['response_received']) * 1000
            
            result = {
                "endpoint": endpoint,
                "description": description,
                "status_code": response.status_code,
                "total_time_ms": total_time,
                "parsing_time_ms": parsing_time,
                "network_time_ms": total_time - parsing_time,
                "data_size_bytes": data_size,
                "data_size_mb": data_size / (1024 * 1024),
                "throughput_mbps": (data_size / (1024 * 1024)) / (total_time / 1000) if total_time > 0 else 0,
                "timestamp": datetime.now().isoformat(),
                "success": response.status_code == 200
            }
            
            # ğŸ“Š æ€§èƒ½åˆ†æ
            if total_time > 5000:
                logger.warning(f"ğŸš¨ ææ…¢å“åº”: {total_time:.2f}ms")
            elif total_time > 2000:
                logger.warning(f"âš ï¸ æ…¢å“åº”: {total_time:.2f}ms")
            else:
                logger.info(f"âœ… æ­£å¸¸å“åº”: {total_time:.2f}ms")
            
            logger.info(f"   ğŸ“¦ æ•°æ®å¤§å°: {data_size / 1024:.2f} KB")
            logger.info(f"   ğŸŒ ç½‘ç»œè€—æ—¶: {result['network_time_ms']:.2f}ms")
            logger.info(f"   ğŸ”§ è§£æè€—æ—¶: {parsing_time:.2f}ms")
            logger.info(f"   ğŸ“Š ååé‡: {result['throughput_mbps']:.2f} MB/s")
            
            self.results["api_tests"].append(result)
            return result
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            error_result = {
                "endpoint": endpoint,
                "description": description,
                "error": str(e),
                "success": False,
                "timestamp": datetime.now().isoformat()
            }
            self.results["api_tests"].append(error_result)
            return error_result
    
    def test_concurrent_load(self, endpoint: str, concurrent_users: int = 5):
        """æµ‹è¯•å¹¶å‘è´Ÿè½½å¯¹æ€§èƒ½çš„å½±å“"""
        url = f"{self.base_url}{endpoint}"
        logger.info(f"ğŸ”„ å¹¶å‘æµ‹è¯•: {concurrent_users} ç”¨æˆ·åŒæ—¶è®¿é—® {url}")
        
        def single_request():
            start_time = time.time()
            try:
                response = requests.get(url, timeout=30)
                end_time = time.time()
                return {
                    "success": True,
                    "duration": (end_time - start_time) * 1000,
                    "status_code": response.status_code,
                    "size": len(response.content)
                }
            except Exception as e:
                end_time = time.time()
                return {
                    "success": False,
                    "duration": (end_time - start_time) * 1000,
                    "error": str(e)
                }
        
        # æ‰§è¡Œå¹¶å‘æµ‹è¯•
        start_time = time.time()
        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(single_request) for _ in range(concurrent_users)]
            results = [future.result() for future in as_completed(futures)]
        end_time = time.time()
        
        # åˆ†æç»“æœ
        successful_results = [r for r in results if r["success"]]
        failed_results = [r for r in results if not r["success"]]
        
        if successful_results:
            durations = [r["duration"] for r in successful_results]
            concurrent_result = {
                "endpoint": endpoint,
                "concurrent_users": concurrent_users,
                "total_test_time": (end_time - start_time) * 1000,
                "success_count": len(successful_results),
                "failure_count": len(failed_results),
                "average_response_time": sum(durations) / len(durations),
                "min_response_time": min(durations),
                "max_response_time": max(durations),
                "requests_per_second": len(successful_results) / (end_time - start_time),
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info(f"ğŸ“Š å¹¶å‘æµ‹è¯•ç»“æœ:")
            logger.info(f"   æˆåŠŸ: {concurrent_result['success_count']}/{concurrent_users}")
            logger.info(f"   å¹³å‡å“åº”: {concurrent_result['average_response_time']:.2f}ms")
            logger.info(f"   å“åº”èŒƒå›´: {concurrent_result['min_response_time']:.2f}ms - {concurrent_result['max_response_time']:.2f}ms")
            logger.info(f"   QPS: {concurrent_result['requests_per_second']:.2f}")
            
            self.results["concurrent_tests"].append(concurrent_result)
            return concurrent_result
        
        return None
    
    def analyze_system_resources(self):
        """åˆ†æç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ"""
        logger.info("ğŸ–¥ï¸ åˆ†æç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ")
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # å†…å­˜ä½¿ç”¨ç‡
        memory = psutil.virtual_memory()
        
        # ç£ç›˜I/O
        disk_io = psutil.disk_io_counters()
        
        # ç½‘ç»œI/O
        network_io = psutil.net_io_counters()
        
        resource_analysis = {
            "cpu_percent": cpu_percent,
            "memory_total_gb": memory.total / (1024**3),
            "memory_used_gb": memory.used / (1024**3),
            "memory_percent": memory.percent,
            "disk_read_mb": disk_io.read_bytes / (1024**2) if disk_io else 0,
            "disk_write_mb": disk_io.write_bytes / (1024**2) if disk_io else 0,
            "network_sent_mb": network_io.bytes_sent / (1024**2) if network_io else 0,
            "network_recv_mb": network_io.bytes_recv / (1024**2) if network_io else 0,
            "timestamp": datetime.now().isoformat()
        }
        
        logger.info(f"ğŸ’» CPUä½¿ç”¨ç‡: {cpu_percent}%")
        logger.info(f"ğŸ§  å†…å­˜ä½¿ç”¨ç‡: {memory.percent}% ({memory.used / (1024**3):.2f}GB / {memory.total / (1024**3):.2f}GB)")
        
        self.results["bottleneck_analysis"]["system_resources"] = resource_analysis
        return resource_analysis
    
    def run_comprehensive_diagnosis(self):
        """è¿è¡Œå…¨é¢è¯Šæ–­"""
        logger.info("ğŸš€ å¼€å§‹å…¨é¢æ€§èƒ½ç“¶é¢ˆè¯Šæ–­")
        
        # 1. ç³»ç»Ÿèµ„æºåˆ†æ
        self.analyze_system_resources()
        
        # 2. æ ¸å¿ƒAPIæ€§èƒ½æµ‹è¯•
        core_apis = [
            ("/views-optimized/users/17", "ç”¨æˆ·ä¿¡æ¯ä¼˜åŒ–æ¥å£"),
            ("/views-optimized/departments", "éƒ¨é—¨ä¿¡æ¯ä¼˜åŒ–æ¥å£"),
            ("/views-optimized/payroll-component-definitions?is_active=true&size=100", "è–ªèµ„ç»„ä»¶å®šä¹‰æ¥å£"),
            ("/simple-payroll/periods?size=50", "è–ªèµ„å‘¨æœŸæ¥å£"),
            ("/views-optimized/lookup-values-public?lookup_type_code=GENDER", "Lookupå€¼æ¥å£")
        ]
        
        logger.info(f"ğŸ“‹ æµ‹è¯• {len(core_apis)} ä¸ªæ ¸å¿ƒAPI")
        for endpoint, description in core_apis:
            self.test_single_api_detailed(endpoint, description)
            time.sleep(0.5)  # é¿å…è¿‡è½½
        
        # 3. å¹¶å‘è´Ÿè½½æµ‹è¯•ï¼ˆé€‰æ‹©æœ€æ…¢çš„APIï¼‰
        slowest_api = None
        slowest_time = 0
        for test in self.results["api_tests"]:
            if test.get("success") and test.get("total_time_ms", 0) > slowest_time:
                slowest_time = test["total_time_ms"]
                slowest_api = test["endpoint"]
        
        if slowest_api:
            logger.info(f"ğŸ”„ å¯¹æœ€æ…¢APIè¿›è¡Œå¹¶å‘æµ‹è¯•: {slowest_api}")
            self.test_concurrent_load(slowest_api, concurrent_users=3)
        
        # 4. ç”Ÿæˆè¯Šæ–­å»ºè®®
        self.generate_bottleneck_recommendations()
        
        # 5. ä¿å­˜ç»“æœ
        self.save_results()
        
        logger.info("âœ… æ€§èƒ½ç“¶é¢ˆè¯Šæ–­å®Œæˆ")
    
    def generate_bottleneck_recommendations(self):
        """ç”Ÿæˆç“¶é¢ˆåˆ†æå»ºè®®"""
        recommendations = []
        
        # åˆ†æAPIå“åº”æ—¶é—´
        slow_apis = [test for test in self.results["api_tests"] 
                    if test.get("success") and test.get("total_time_ms", 0) > 2000]
        
        if slow_apis:
            recommendations.append(f"å‘ç° {len(slow_apis)} ä¸ªæ…¢APIï¼ˆ>2ç§’ï¼‰ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–")
            
            # åˆ†ææ•°æ®å¤§å° vs å“åº”æ—¶é—´
            for api in slow_apis:
                if api.get("data_size_mb", 0) > 1:  # è¶…è¿‡1MB
                    recommendations.append(f"API {api['endpoint']} è¿”å›æ•°æ®è¿‡å¤§ï¼ˆ{api['data_size_mb']:.2f}MBï¼‰ï¼Œå»ºè®®åˆ†é¡µæˆ–æ•°æ®å‹ç¼©")
                elif api.get("throughput_mbps", 0) < 1:  # ååé‡å°äº1MB/s
                    recommendations.append(f"API {api['endpoint']} ååé‡è¿‡ä½ï¼ˆ{api['throughput_mbps']:.2f}MB/sï¼‰ï¼Œå¯èƒ½å­˜åœ¨æœåŠ¡å™¨å¤„ç†ç“¶é¢ˆ")
        
        # åˆ†æç³»ç»Ÿèµ„æº
        resources = self.results["bottleneck_analysis"].get("system_resources", {})
        if resources.get("cpu_percent", 0) > 80:
            recommendations.append("CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨è®¡ç®—å¯†é›†å‹æ“ä½œ")
        if resources.get("memory_percent", 0) > 90:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼æˆ–æ•°æ®ç¼“å­˜è¿‡å¤š")
        
        # åˆ†æå¹¶å‘æ€§èƒ½
        concurrent_tests = self.results.get("concurrent_tests", [])
        for test in concurrent_tests:
            if test.get("max_response_time", 0) > test.get("average_response_time", 0) * 3:
                recommendations.append(f"å¹¶å‘è®¿é—®æ—¶å“åº”æ—¶é—´æ³¢åŠ¨è¾ƒå¤§ï¼Œå¯èƒ½å­˜åœ¨èµ„æºç«äº‰")
        
        self.results["recommendations"] = recommendations
        
        logger.info("ğŸ’¡ è¯Šæ–­å»ºè®®:")
        for i, rec in enumerate(recommendations, 1):
            logger.info(f"   {i}. {rec}")
    
    def save_results(self):
        """ä¿å­˜è¯Šæ–­ç»“æœ"""
        filename = f"performance_bottleneck_diagnosis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“„ è¯Šæ–­ç»“æœå·²ä¿å­˜åˆ°: {filename}")

def main():
    """ä¸»å‡½æ•°"""
    diagnoser = PerformanceBottleneckDiagnoser()
    diagnoser.run_comprehensive_diagnosis()

if __name__ == "__main__":
    main() 