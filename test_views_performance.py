#!/usr/bin/env python3
"""
æ ¸å¿ƒä¸šåŠ¡è§†å›¾æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰é‡è¦è§†å›¾çš„æŸ¥è¯¢æ€§èƒ½ï¼Œè¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
"""
import os
import sys
import time
import json
from datetime import datetime
import asyncio
import traceback
from typing import Dict, List, Any

import psycopg2
from psycopg2.extras import RealDictCursor

# æ•°æ®åº“è¿æ¥é…ç½®
DATABASE_URL = "postgresql+psycopg2://postgres:810705@pg.debian.ziikoo.com:25432/salary_system_v2"
DB_CONFIG = {
    'host': 'pg.debian.ziikoo.com',
    'port': 25432,
    'database': 'salary_system_v2',
    'user': 'postgres',
    'password': '810705'
}

class ViewPerformanceTester:
    """è§†å›¾æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.conn = None
        self.results = []
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = psycopg2.connect(**DB_CONFIG)
            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            sys.exit(1)
            
    def disconnect(self):
        """æ–­å¼€æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            print("âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
    
    def execute_explain_analyze(self, query: str, test_name: str) -> Dict[str, Any]:
        """æ‰§è¡ŒEXPLAIN ANALYZEæŸ¥è¯¢"""
        try:
            with self.conn.cursor(cursor_factory=RealDictCursor) as cursor:
                start_time = time.time()
                cursor.execute(f"EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) {query}")
                result_row = cursor.fetchone()
                explain_result = result_row['QUERY PLAN'][0]
                end_time = time.time()
                
                # æå–å…³é”®æ€§èƒ½æŒ‡æ ‡
                execution_time = explain_result['Execution Time']
                planning_time = explain_result['Planning Time']
                
                result = {
                    'test_name': test_name,
                    'query': query,
                    'execution_time_ms': execution_time,
                    'planning_time_ms': planning_time,
                    'total_time_ms': execution_time + planning_time,
                    'measured_time_ms': (end_time - start_time) * 1000,
                    'explain_output': explain_result,
                    'timestamp': datetime.now().isoformat()
                }
                
                print(f"ğŸ“Š {test_name}: {execution_time:.2f}ms")
                return result
                
        except Exception as e:
            error_result = {
                'test_name': test_name,
                'query': query,
                'error': str(e),
                'traceback': traceback.format_exc(),
                'timestamp': datetime.now().isoformat()
            }
            print(f"âŒ {test_name}: é”™è¯¯ - {e}")
            return error_result
    
    def test_view_queries(self):
        """æµ‹è¯•æ ¸å¿ƒè§†å›¾æŸ¥è¯¢æ€§èƒ½"""
        
        test_queries = [
            # 1. å‘˜å·¥åŸºç¡€ä¿¡æ¯è§†å›¾
            {
                'name': 'å‘˜å·¥åŸºç¡€ä¿¡æ¯è§†å›¾(åŸºæœ¬æŸ¥è¯¢)',
                'query': 'SELECT * FROM reports.v_employees_basic LIMIT 100;'
            },
            {
                'name': 'å‘˜å·¥åŸºç¡€ä¿¡æ¯è§†å›¾(å¸¦è¿‡æ»¤)',
                'query': "SELECT * FROM reports.v_employees_basic WHERE department_name = 'åŠå…¬å®¤' LIMIT 50;"
            },
            
            # 2. è–ªèµ„æ¡ç›®åŸºç¡€è§†å›¾
            {
                'name': 'è–ªèµ„æ¡ç›®åŸºç¡€è§†å›¾(åŸºæœ¬æŸ¥è¯¢)',
                'query': 'SELECT * FROM reports.v_payroll_entries_basic LIMIT 100;'
            },
            {
                'name': 'è–ªèµ„æ¡ç›®åŸºç¡€è§†å›¾(æŒ‰éƒ¨é—¨)',
                'query': "SELECT * FROM reports.v_payroll_entries_basic WHERE department_name = 'åŠå…¬å®¤' LIMIT 50;"
            },
            
            # 3. è–ªèµ„æ¡ç›®è¯¦æƒ…è§†å›¾(åŒ…å«JSONB)
            {
                'name': 'è–ªèµ„æ¡ç›®è¯¦æƒ…è§†å›¾(åŸºæœ¬æŸ¥è¯¢)',
                'query': 'SELECT * FROM reports.v_payroll_entries_detailed LIMIT 50;'
            },
            {
                'name': 'è–ªèµ„æ¡ç›®è¯¦æƒ…è§†å›¾(å¸¦JSONBè¿‡æ»¤)',
                'query': "SELECT * FROM reports.v_payroll_entries_detailed WHERE earnings_details ? 'BASIC_SALARY' LIMIT 20;"
            },
            
            # 4. ç»¼åˆè–ªèµ„è¯¦æƒ…è§†å›¾(æœ€å¤æ‚)
            {
                'name': 'ç»¼åˆè–ªèµ„è¯¦æƒ…è§†å›¾(å°æ ·æœ¬)',
                'query': 'SELECT * FROM reports.v_comprehensive_employee_payroll LIMIT 10;'
            },
            {
                'name': 'ç»¼åˆè–ªèµ„è¯¦æƒ…è§†å›¾(å¸¦æ¡ä»¶)',
                'query': "SELECT * FROM reports.v_comprehensive_employee_payroll WHERE \"éƒ¨é—¨åç§°\" = 'åŠå…¬å®¤' LIMIT 5;"
            },
            
            # 5. è–ªèµ„å‘¨æœŸè¯¦æƒ…è§†å›¾
            {
                'name': 'è–ªèµ„å‘¨æœŸè¯¦æƒ…è§†å›¾',
                'query': 'SELECT * FROM reports.v_payroll_periods_detail ORDER BY start_date DESC LIMIT 20;'
            },
            
            # 6. è–ªèµ„è¿è¡Œè¯¦æƒ…è§†å›¾
            {
                'name': 'è–ªèµ„è¿è¡Œè¯¦æƒ…è§†å›¾',
                'query': 'SELECT * FROM reports.v_payroll_runs_detail ORDER BY run_date DESC LIMIT 20;'
            },
            
            # 7. è–ªèµ„ç»„ä»¶ä½¿ç”¨æƒ…å†µè§†å›¾(èšåˆæŸ¥è¯¢)
            {
                'name': 'è–ªèµ„ç»„ä»¶ä½¿ç”¨æƒ…å†µè§†å›¾',
                'query': 'SELECT * FROM reports.v_payroll_component_usage ORDER BY usage_count DESC LIMIT 30;'
            },
            
            # 8. è–ªèµ„æ±‡æ€»åˆ†æè§†å›¾
            {
                'name': 'è–ªèµ„æ±‡æ€»åˆ†æè§†å›¾',
                'query': 'SELECT * FROM reports.v_payroll_summary_analysis ORDER BY start_date DESC LIMIT 20;'
            },
            
            # 9. å‘˜å·¥è–ªèµ„å†å²è§†å›¾
            {
                'name': 'å‘˜å·¥è–ªèµ„å†å²è§†å›¾',
                'query': 'SELECT * FROM reports.v_employee_salary_history WHERE period_rank <= 3 LIMIT 50;'
            },
            
            # 10. å®¡è®¡æ¦‚è§ˆè§†å›¾
            {
                'name': 'å®¡è®¡æ¦‚è§ˆè§†å›¾',
                'query': 'SELECT * FROM payroll.audit_overview ORDER BY payroll_run_id DESC LIMIT 20;'
            },
            
            # 11. å®¡è®¡å¼‚å¸¸è¯¦æƒ…è§†å›¾
            {
                'name': 'å®¡è®¡å¼‚å¸¸è¯¦æƒ…è§†å›¾',
                'query': 'SELECT * FROM payroll.audit_anomalies_detail WHERE severity = \'ERROR\' LIMIT 20;'
            },
            
            # 12. æµ‹è¯•å¤æ‚èšåˆæŸ¥è¯¢
            {
                'name': 'å‘˜å·¥éƒ¨é—¨è–ªèµ„ç»Ÿè®¡(å¤æ‚èšåˆ)',
                'query': '''
                SELECT 
                    department_name,
                    COUNT(*) as employee_count,
                    AVG(gross_pay) as avg_gross_pay,
                    SUM(gross_pay) as total_gross_pay
                FROM reports.v_payroll_entries_basic 
                GROUP BY department_name 
                ORDER BY total_gross_pay DESC;
                '''
            },
            
            # 13. æµ‹è¯•JSONBæŸ¥è¯¢æ€§èƒ½
            {
                'name': 'JSONBå­—æ®µæŸ¥è¯¢æ€§èƒ½æµ‹è¯•',
                'query': '''
                SELECT 
                    employee_code,
                    earnings_details->'BASIC_SALARY'->>'amount' as basic_salary,
                    deductions_details->'PERSONAL_INCOME_TAX'->>'amount' as tax
                FROM reports.v_payroll_entries_detailed 
                WHERE earnings_details ? 'BASIC_SALARY' 
                LIMIT 100;
                '''
            },
            
            # 14. æµ‹è¯•é€’å½’CTEæ€§èƒ½
            {
                'name': 'é€’å½’CTEæ€§èƒ½æµ‹è¯•(äººå‘˜å±‚æ¬¡)',
                'query': '''
                WITH RECURSIVE category_tree AS (
                    SELECT id, name, parent_category_id, 0 as level
                    FROM hr.personnel_categories 
                    WHERE parent_category_id IS NULL
                    
                    UNION ALL
                    
                    SELECT pc.id, pc.name, pc.parent_category_id, ct.level + 1
                    FROM hr.personnel_categories pc
                    INNER JOIN category_tree ct ON pc.parent_category_id = ct.id
                )
                SELECT * FROM category_tree ORDER BY level, name;
                '''
            }
        ]
        
        print("ğŸš€ å¼€å§‹æ‰§è¡Œè§†å›¾æ€§èƒ½æµ‹è¯•...")
        print("="*80)
        
        for i, test in enumerate(test_queries, 1):
            print(f"\n{i:2d}. æµ‹è¯•: {test['name']}")
            result = self.execute_explain_analyze(test['query'], test['name'])
            self.results.append(result)
            
            # çŸ­æš‚åœé¡¿ï¼Œé¿å…å¯¹æ•°æ®åº“é€ æˆè¿‡å¤§å‹åŠ›
            time.sleep(0.1)
        
        print("\n" + "="*80)
        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆ!")
        
    def analyze_results(self):
        """åˆ†ææµ‹è¯•ç»“æœ"""
        print("\nğŸ“ˆ æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("="*80)
        
        # æŒ‰æ‰§è¡Œæ—¶é—´æ’åº
        valid_results = [r for r in self.results if 'execution_time_ms' in r]
        sorted_results = sorted(valid_results, key=lambda x: x['execution_time_ms'], reverse=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        execution_times = [r['execution_time_ms'] for r in valid_results]
        if execution_times:
            avg_time = sum(execution_times) / len(execution_times)
            max_time = max(execution_times)
            min_time = min(execution_times)
            
            print(f"ğŸ“Š æµ‹è¯•ç»Ÿè®¡:")
            print(f"   - æ€»æµ‹è¯•æ•°: {len(self.results)}")
            print(f"   - æˆåŠŸæµ‹è¯•: {len(valid_results)}")
            print(f"   - å¤±è´¥æµ‹è¯•: {len(self.results) - len(valid_results)}")
            print(f"   - å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.2f}ms")
            print(f"   - æœ€é•¿æ‰§è¡Œæ—¶é—´: {max_time:.2f}ms")
            print(f"   - æœ€çŸ­æ‰§è¡Œæ—¶é—´: {min_time:.2f}ms")
        
        # æ€§èƒ½é—®é¢˜è¯†åˆ«
        print(f"\nâš ï¸  æ€§èƒ½å…³æ³¨ç‚¹ (æ‰§è¡Œæ—¶é—´ > 100ms):")
        slow_queries = [r for r in valid_results if r['execution_time_ms'] > 100]
        
        if slow_queries:
            for result in slow_queries:
                print(f"   - {result['test_name']}: {result['execution_time_ms']:.2f}ms")
        else:
            print("   - æš‚æ— æ˜æ˜¾æ€§èƒ½é—®é¢˜")
        
        # Top 5 æœ€æ…¢æŸ¥è¯¢
        print(f"\nğŸŒ æ‰§è¡Œæ—¶é—´æœ€é•¿çš„5ä¸ªæŸ¥è¯¢:")
        for i, result in enumerate(sorted_results[:5], 1):
            print(f"   {i}. {result['test_name']}: {result['execution_time_ms']:.2f}ms")
        
        # é”™è¯¯æŠ¥å‘Š
        error_results = [r for r in self.results if 'error' in r]
        if error_results:
            print(f"\nâŒ é”™è¯¯æŸ¥è¯¢:")
            for result in error_results:
                print(f"   - {result['test_name']}: {result['error']}")
    
    def save_results(self, filename: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°JSONæ–‡ä»¶"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"view_performance_test_results_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        return filename
    
    def run_full_test(self):
        """è¿è¡Œå®Œæ•´çš„æ€§èƒ½æµ‹è¯•"""
        try:
            self.connect()
            self.test_view_queries()
            self.analyze_results()
            filename = self.save_results()
            return filename
        finally:
            self.disconnect()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ ¸å¿ƒä¸šåŠ¡è§†å›¾æ€§èƒ½æµ‹è¯•")
    print("="*80)
    
    tester = ViewPerformanceTester()
    result_file = tester.run_full_test()
    
    print(f"\nğŸ¯ å»ºè®®ä¸‹ä¸€æ­¥:")
    print(f"   1. æŸ¥çœ‹è¯¦ç»†ç»“æœ: cat {result_file}")
    print(f"   2. åˆ†ææ…¢æŸ¥è¯¢çš„æ‰§è¡Œè®¡åˆ’")
    print(f"   3. è€ƒè™‘åˆ›å»ºç‰©åŒ–è§†å›¾ä¼˜åŒ–æ€§èƒ½")
    print(f"   4. ä¼˜åŒ–JSONBå­—æ®µæŸ¥è¯¢")

if __name__ == "__main__":
    main() 